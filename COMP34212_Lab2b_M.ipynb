{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_SLMzgGIpjE"
   },
   "source": [
    "Advanced Convolutional Neural Networks (CNNs) with CIFAR-10 dataset\n",
    "=========\n",
    "\n",
    "In this tutorial we will learn how to use more complex CNNs, showing that the training of a __deeper__ CNN can improve the performance of the model. We will also explore the concept of __data augmentation__ to understand how to increase the variability of the training set by, for example, rotating the original images to generate new training stimuli.\n",
    "\n",
    "This tutorail will use the CIFAR-10 training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKafL_SXIpjI"
   },
   "source": [
    "**CNN for CIFAR-10**\n",
    "\n",
    "To work with more complex CNNs, we will now use a more complex training dataset called __CIFAR-10__. https://www.cs.toronto.edu/~kriz/cifar.html . CIFAR-10 is a benchamark machine learning set of low-resolution, colour images. It includes 60000 32x32 colour (using 3 RGB colour channels) images in these 10 classes of objects: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. Each class has 6000. There are 50000 training images and 10000 test images. This dataset is enclosed in the default Anaconda KERAS package. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSw16YYkIpjK"
   },
   "source": [
    "**Initialisation of the program**\n",
    "\n",
    "The program starts with the importing of typical Keras and other Python service modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x595vK3pIpjN",
    "outputId": "422206db-2d3f-4bd4-d07c-b205eb6007ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 02:48:39.162581: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-25 02:48:39.162607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-25 02:48:39.163637: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-25 02:48:39.169177: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-25 02:48:39.809936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# importing of modules for CIFAR-10 CNN \n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# importing of service libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available? : True\n",
      "WARNING:tensorflow:From /tmp/ipykernel_19972/4111022288.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is cuDNN available? : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 02:48:40.793839: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:40.860577: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:40.860762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:40.938412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:40.938581: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:40.938733: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:40.938853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 6600 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check CUDA\n",
    "print(\"Is CUDA available? :\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Check cuDNN\n",
    "print(\"Is cuDNN available? :\", tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 02:48:40.943731: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:40.943927: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:40.944054: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# This line ensures TensorFlow will use the GPU if available\n",
    "# tf.config.set_visible_devices(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"Using GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx5--x5hIpjV"
   },
   "source": [
    "The following constant and variable definitions are needed for the network and training parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1SvoRcMIpjX",
    "outputId": "51831c4b-8f85-4570-ee52-326ed271a935",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main variables initialised.\n"
     ]
    }
   ],
   "source": [
    "#training constants\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCH = 40 # use 20 for best initial results\n",
    "N_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# OPTIM = RMSprop()\n",
    "\n",
    "print('Main variables initialised.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpuekS__Ipjd"
   },
   "source": [
    "Constant definition for the training set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWaibn5BIpje",
    "outputId": "c1855f56-e2f6-445c-9ec9-59b638dd6d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image variables initialisation\n"
     ]
    }
   ],
   "source": [
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "print('Image variables initialisation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcOhLgJ8Ipjk"
   },
   "source": [
    "__CIFAR-10 data loading and processing__\n",
    "\n",
    "Loading and preparation of the CIFAR-10 training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVzGwn80Ipjm",
    "outputId": "b5c2f64e-2821-4813-af77-ef63090b1887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "(input_X_train, output_y_train), (input_X_test, output_y_test) = cifar10.load_data()\n",
    "print('input_X_train shape:', input_X_train.shape)\n",
    "print(input_X_train.shape[0], 'train samples')\n",
    "print(input_X_test.shape[0], 'test samples')\n",
    " \n",
    "# convert to categorical\n",
    "output_Y_train = utils.to_categorical(output_y_train, N_CLASSES)\n",
    "output_Y_test = utils.to_categorical(output_y_test, N_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "input_X_train = input_X_train.astype('float32')\n",
    "input_X_test = input_X_test.astype('float32')\n",
    "input_X_train /= 255\n",
    "input_X_test /= 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation\n",
    "-------------\n",
    "\n",
    "To further improve the performance of the model, it is advisable to use a larger training set, to expose the network to more variations of the images.\n",
    "One way to achieve this, without having to collect new images from the real world, is to __augment__ the existing images with multiple types of transformations of the dataset stimuli. This can include rotation of the image, rescaling, horizontal/vertical flip, zooming, channel shift, etc.\n",
    "\n",
    "Below is an example of the code that augments the current datase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training set images...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.datasets import cifar10\n",
    "\n",
    "#load dataset\n",
    "#(input_X_train, output_y_train), (input_X_test, output_y_test) = cifar10.load_data()\n",
    "\n",
    "# augumenting\n",
    "print(\"Augmenting training set images...\")\n",
    "    \n",
    "datagen = ImageDataGenerator(\n",
    "   rotation_range=20,\n",
    "   width_shift_range=0.2,\n",
    "   height_shift_range=0.2,\n",
    "   zoom_range=0.2,\n",
    "   horizontal_flip=True,\n",
    "   fill_mode='nearest')\n",
    "\n",
    "# rotation_range is a value in degrees (0 - 180) for randomly rotating pictures\n",
    "# width_shift and height_shift are ranges for randomly translating pictures vertically or horizontally\n",
    "# zoom_range is for randomly zooming pictures \n",
    "# horizontal_flip is for randomly flipping the images horizontally\n",
    "# fill_mode fills in new pixels that can appear after a rotation or a shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "steps_per_epoch = input_X_train.shape[0] // BATCH_SIZE\n",
    "\n",
    "# Split the data into 80% training and 20% validation\n",
    "input_X_train_split, input_X_val, output_Y_train_split, output_Y_val = train_test_split(\n",
    "    input_X_train, output_Y_train, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x shape: (128, 32, 32, 3)\n",
      "Batch y shape: (128, 10)\n"
     ]
    }
   ],
   "source": [
    "# # Create a generator object\n",
    "# train_generator = datagen.flow(input_X_train, output_Y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Creating the training generator\n",
    "train_generator = datagen.flow(\n",
    "    input_X_train_split, \n",
    "    output_Y_train_split, \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Creating the validation generator\n",
    "validation_generator = datagen.flow(\n",
    "    input_X_val, \n",
    "    output_Y_val, \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Test generator output\n",
    "x_batch, y_batch = next(train_generator)\n",
    "print(\"Batch x shape:\", x_batch.shape)\n",
    "print(\"Batch y shape:\", y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1o9i5nqDIpkO"
   },
   "source": [
    "A deeper CNN\n",
    "-------------\n",
    "\n",
    "To improve the performance of the network on the CIFAR-10 dataset, it is possible to use a deeper CNN, with a chain of multiple convolution and pooling layers.\n",
    "The following network will be used:\n",
    "\n",
    "conv+conv+maxpool+dropout+conv+conv+maxpool\n",
    "\n",
    "The final classification layers will use the standard:\n",
    "\n",
    "dense+dropout+dense\n",
    "\n",
    "All the layers will use the reLu function, except the final one with the Softmax function necessary for the categorical classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VmaK6n4AIpkP",
    "outputId": "72f4485b-572b-4989-b03e-07be8090c7c1"
   },
   "outputs": [],
   "source": [
    "# # REUSE THE SAME INITIALISATION CODE AND THE TRAINING AND TEST DATA SET LOADING OPERATION\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization, LeakyReLU\n",
    "\n",
    "# Complex DNN model definition\n",
    "# model = Sequential()\n",
    " \n",
    "# model.add(Conv2D(128, kernel_size=3, padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    " \n",
    "# model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(128, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    " \n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(N_CLASSES))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# # OPTIM = SGD(lr=0.01)\n",
    "# # OPTIM = RMSprop(lr=0.01)\n",
    "# OPTIM = Adam(lr=0.01)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define model architecture\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Conv2D(64, (3, 3), padding='same'),\n",
    "#     Activation('relu'),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Dropout(0.2),  # Slightly reduced dropout\n",
    "\n",
    "#     Conv2D(128, (3, 3), padding='same'),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Conv2D(128, (3, 3)),\n",
    "#     Activation('relu'),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Dropout(0.3),  # Slightly reduced dropout\n",
    "\n",
    "#     Flatten(),\n",
    "#     Dense(512, activation='relu'),\n",
    "#     Dropout(0.4),  # Slightly reduced dropout\n",
    "#     Dense(N_CLASSES, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# optimizer = Adam(lr=0.001)\n",
    "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Callbacks\n",
    "# callbacks = [\n",
    "#     EarlyStopping(monitor='val_accuracy', patience=5, verbose=1),\n",
    "#     ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "# ]\n",
    "\n",
    "# # Simplified data augmentation\n",
    "# data_generator = ImageDataGenerator(\n",
    "#     rotation_range=10,  # Less aggressive rotation\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "#     horizontal_flip=True\n",
    "# )\n",
    "\n",
    "# # Model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1341226 (5.12 MB)\n",
      "Trainable params: 1341226 (5.12 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 02:48:42.022700: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:42.022890: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:42.023018: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:42.023176: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:42.023303: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-25 02:48:42.023396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6600 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization, LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional block\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second convolutional block\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Third convolutional block\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten and dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_WU_cUNkmr-"
   },
   "source": [
    "**Training of the deeper CNN**\n",
    "\n",
    "Let's train (fit) this new model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctRJSHkVkmr_",
    "outputId": "c00b1c5f-28e7-43aa-cc3c-0384b01ad3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 02:48:43.214008: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-04-25 02:48:43.394406: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-04-25 02:48:43.493939: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-25 02:48:43.884085: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-25 02:48:44.560719: I external/local_xla/xla/service/service.cc:168] XLA service 0x751e08bf4640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-25 02:48:44.560741: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2024-04-25 02:48:44.566038: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714009724.647671   20022 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 22s 58ms/step - loss: 1.9204 - accuracy: 0.2785 - val_loss: 1.6746 - val_accuracy: 0.3766\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - 17s 55ms/step - loss: 1.6077 - accuracy: 0.4050 - val_loss: 1.4352 - val_accuracy: 0.4606\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 1.4427 - accuracy: 0.4708 - val_loss: 1.3497 - val_accuracy: 0.5049\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 1.3382 - accuracy: 0.5157 - val_loss: 1.2239 - val_accuracy: 0.5561\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 1.2760 - accuracy: 0.5403 - val_loss: 1.1503 - val_accuracy: 0.5812\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 1.2069 - accuracy: 0.5685 - val_loss: 1.0889 - val_accuracy: 0.6139\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - 17s 55ms/step - loss: 1.1564 - accuracy: 0.5889 - val_loss: 1.0635 - val_accuracy: 0.6199\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 1.1140 - accuracy: 0.6043 - val_loss: 1.0290 - val_accuracy: 0.6292\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - 17s 55ms/step - loss: 1.0852 - accuracy: 0.6156 - val_loss: 0.9879 - val_accuracy: 0.6452\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 1.0538 - accuracy: 0.6259 - val_loss: 0.9658 - val_accuracy: 0.6602\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 1.0176 - accuracy: 0.6402 - val_loss: 0.9532 - val_accuracy: 0.6560\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.9944 - accuracy: 0.6497 - val_loss: 0.8931 - val_accuracy: 0.6875\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.9680 - accuracy: 0.6574 - val_loss: 0.8973 - val_accuracy: 0.6804\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - 18s 59ms/step - loss: 0.9510 - accuracy: 0.6698 - val_loss: 0.8784 - val_accuracy: 0.6888\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.9312 - accuracy: 0.6738 - val_loss: 0.8290 - val_accuracy: 0.7097\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.9156 - accuracy: 0.6761 - val_loss: 0.8144 - val_accuracy: 0.7141\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.9007 - accuracy: 0.6840 - val_loss: 0.8174 - val_accuracy: 0.7121\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.8891 - accuracy: 0.6899 - val_loss: 0.8111 - val_accuracy: 0.7189\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.8707 - accuracy: 0.6952 - val_loss: 0.7944 - val_accuracy: 0.7213\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.8608 - accuracy: 0.6972 - val_loss: 0.7868 - val_accuracy: 0.7234\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - 17s 55ms/step - loss: 0.8544 - accuracy: 0.7003 - val_loss: 0.7740 - val_accuracy: 0.7305\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 0.8421 - accuracy: 0.7071 - val_loss: 0.7756 - val_accuracy: 0.7328\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 0.8317 - accuracy: 0.7097 - val_loss: 0.7928 - val_accuracy: 0.7222\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - 17s 55ms/step - loss: 0.8209 - accuracy: 0.7121 - val_loss: 0.7796 - val_accuracy: 0.7333\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 0.8092 - accuracy: 0.7157 - val_loss: 0.7613 - val_accuracy: 0.7359\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 0.8068 - accuracy: 0.7188 - val_loss: 0.7617 - val_accuracy: 0.7357\n",
      "Epoch 27/40\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.8054 - accuracy: 0.7192 - val_loss: 0.7381 - val_accuracy: 0.7378\n",
      "Epoch 28/40\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.7939 - accuracy: 0.7260 - val_loss: 0.7254 - val_accuracy: 0.7503\n",
      "Epoch 29/40\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.7915 - accuracy: 0.7238 - val_loss: 0.7701 - val_accuracy: 0.7281\n",
      "Epoch 30/40\n",
      "312/312 [==============================] - 17s 55ms/step - loss: 0.7792 - accuracy: 0.7301 - val_loss: 0.7334 - val_accuracy: 0.7515\n",
      "Epoch 31/40\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.7812 - accuracy: 0.7270 - val_loss: 0.7297 - val_accuracy: 0.7473\n",
      "Epoch 32/40\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.7697 - accuracy: 0.7336 - val_loss: 0.6825 - val_accuracy: 0.7662\n",
      "Epoch 33/40\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.7605 - accuracy: 0.7354 - val_loss: 0.7122 - val_accuracy: 0.7542\n",
      "Epoch 34/40\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.7654 - accuracy: 0.7355 - val_loss: 0.6935 - val_accuracy: 0.7581\n",
      "Epoch 35/40\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 0.7559 - accuracy: 0.7373 - val_loss: 0.7021 - val_accuracy: 0.7579\n",
      "Epoch 36/40\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.7531 - accuracy: 0.7425 - val_loss: 0.6993 - val_accuracy: 0.7578\n",
      "Epoch 37/40\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.7445 - accuracy: 0.7417 - val_loss: 0.6752 - val_accuracy: 0.7634\n",
      "Epoch 38/40\n",
      "312/312 [==============================] - 17s 55ms/step - loss: 0.7483 - accuracy: 0.7417 - val_loss: 0.7044 - val_accuracy: 0.7581\n",
      "Epoch 39/40\n",
      "312/312 [==============================] - 17s 55ms/step - loss: 0.7396 - accuracy: 0.7424 - val_loss: 0.6658 - val_accuracy: 0.7680\n",
      "Epoch 40/40\n",
      " 76/312 [======>.......................] - ETA: 10s - loss: 0.7374 - accuracy: 0.7414"
     ]
    }
   ],
   "source": [
    "# training/fitting of the complex DNN model \n",
    "# history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, validation_split=VALIDATION_SPLIT,  verbose=VERBOSE)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(input_X_train_split) // BATCH_SIZE,  # Correct calculation for steps per epoch\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(input_X_val) // BATCH_SIZE,  # Correct calculation for validation steps\n",
    "    epochs=N_EPOCH,\n",
    "    verbose=VERBOSE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhkax6pXIpkT"
   },
   "source": [
    "**Analysis of the Deeper CNN results**\n",
    "\n",
    "This generates the test scores and plots for the new, deeper DNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "FfRvK-lUIpkU",
    "outputId": "f08bcd89-00a2-4b1a-c514-0ba83410ca33"
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "score = model.evaluate(input_X_test, output_Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score/loss:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Set up a larger figure to accommodate both subplots side by side\n",
    "plt.figure(figsize=(10, 4))  # Adjust the size as needed\n",
    "\n",
    "# First subplot for accuracy\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Second subplot for loss\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Display the figure with subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-Mzs-L7IpkZ"
   },
   "source": [
    "Data Augmentation\n",
    "-------------\n",
    "\n",
    "To further improve the performance of the model, it is advisable to use a larger training set, to expose the network to more variations of the images.\n",
    "One way to achieve this, without having to collect new images from the real world, is to __augment__ the existing images with multiple types of transformations of the dataset stimuli. This can include rotation of the image, rescaling, horizontal/vertical flip, zooming, channel shift, etc.\n",
    "\n",
    "Below is an example of the code that augments the current datase.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-85_nYLXIpkZ",
    "outputId": "5a395f4a-4765-4dbc-ee9b-e7df04a05705"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.datasets import cifar10\n",
    "\n",
    "#load dataset\n",
    "#(input_X_train, output_y_train), (input_X_test, output_y_test) = cifar10.load_data()\n",
    "\n",
    "# augumenting\n",
    "print(\"Augmenting training set images...\")\n",
    "    \n",
    "datagen = ImageDataGenerator(\n",
    "   rotation_range=20,\n",
    "   width_shift_range=0.2,\n",
    "   height_shift_range=0.2,\n",
    "   zoom_range=0.2,\n",
    "   horizontal_flip=True,\n",
    "   fill_mode='nearest')\n",
    "\n",
    "# rotation_range is a value in degrees (0 - 180) for randomly rotating pictures\n",
    "# width_shift and height_shift are ranges for randomly translating pictures vertically or horizontally\n",
    "# zoom_range is for randomly zooming pictures \n",
    "# horizontal_flip is for randomly flipping the images horizontally\n",
    "# fill_mode fills in new pixels that can appear after a rotation or a shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples:\", input_X_train.shape[0])\n",
    "print(\"Batch size:\", BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = input_X_train.shape[0] // BATCH_SIZE\n",
    "print(\"Steps per epoch:\", steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a generator object\n",
    "# train_generator = datagen.flow(input_X_train, output_Y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "# # Test generator output\n",
    "# x_batch, y_batch = next(train_generator)\n",
    "# print(\"Batch x shape:\", x_batch.shape)\n",
    "# print(\"Batch y shape:\", y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=steps_per_epoch,  # Verify this is calculated correctly\n",
    "#     epochs=N_EPOCH,\n",
    "#     verbose=VERBOSE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWIpifR4Ipkc"
   },
   "source": [
    "__Training with augmented data__\n",
    "\n",
    "The function below used the dynamic generation of the augmented data during the training (just in time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kd_JgZM9Ipkd",
    "outputId": "a1ba44e7-87da-40a8-8aee-6fdcb702bf00"
   },
   "outputs": [],
   "source": [
    "\n",
    "# #fit the dataset\n",
    "# datagen.fit(input_X_train)\n",
    "\n",
    "\n",
    "# # train by fitting the model on batches with real-time data augmentation\n",
    "# history = model.fit(datagen.flow(input_X_train, output_Y_train, batch_size=BATCH_SIZE), steps_per_epoch=input_X_train.shape[0]//BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0ZLORlPIpkh"
   },
   "source": [
    "**Analysis of the Data Augmented, Deeper CNN results**\n",
    "\n",
    "This generates the test scores and plots for the deeper DNN trained on the augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "BxZG9aM2Ipki",
    "outputId": "f933118e-27aa-4a70-ac96-e2313d2e435a"
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "score = model.evaluate(input_X_test, output_Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score/loss:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "#plt.plot(mo)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Bwi-kLYIpkl"
   },
   "source": [
    "Below is a commented different example of a data augmentation approach. \n",
    "\n",
    "But we have carried out plenty of slow, long simulations for this class, and we can stop here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_JAWfc4Ipkm"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(input_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouCjBST_Ipkq"
   },
   "source": [
    "Conclusions\n",
    "-------------\n",
    "\n",
    "Today we learned to train more complex DNNs, and to use data augmentation to further improve the network training and performance.\n",
    "\n",
    "**Copyright (c)** 2022 Angelo Cangelosi, MIT License. Code and examples adapted from Gulli & Pal (2017) Deep Learning with Kera. Punkt Publishing. With support from Wenjie Huang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
